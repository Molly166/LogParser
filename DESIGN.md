# 项目设计思路文档

## 一、项目概述

这是一个日志解析器MVP（最小可行产品），用于从结构化的日志文件中提取关键信息，主要提取三个核心字段：用户输入（query）、账单信息（bill_info）、大模型回复（reply）。

## 二、设计原则

### 1. **灵活性优先（Flexibility First）**
- **不写死代码**：字段提取逻辑可扩展，便于后续添加新字段
- **多格式支持**：支持JSON、CSV、TXT三种输出格式，满足不同使用场景
- **容错机制**：标准JSON解析失败时自动切换到正则表达式备用方案

### 2. **鲁棒性（Robustness）**
- **双重解析策略**：优先使用标准JSON解析，失败时使用正则表达式备用方案
- **缺失字段处理**：即使核心字段缺失，仍输出记录，缺失字段显示为null
- **特殊字符处理**：正确处理中文引号、转义字符等特殊情况

### 3. **用户体验（User Experience）**
- **简单易用**：命令行接口简洁明了，一键完成解析
- **自动命名**：输出文件自动命名为`日志名_result.json`，方便区分
- **结果预览**：支持`--show`参数在控制台预览解析结果

## 三、架构设计

### 1. 模块化设计

```
GETLOG/
├── src/
│   ├── log_parser.py    # 核心解析器类（业务逻辑层）
│   └── main.py          # 命令行入口（接口层）
├── tests/               # 测试文件
├── output/              # 输出目录
└── logs/                # 日志文件目录
```

**分层架构：**
- **接口层（main.py）**：处理命令行参数、用户交互
- **业务逻辑层（log_parser.py）**：核心解析逻辑、数据提取
- **数据层**：日志文件输入、结果文件输出

### 2. 核心类设计：LogParser

```python
class LogParser:
    # 核心方法
    - parse_log_line()      # 解析单行日志
    - parse_log_file()      # 解析整个文件
    - save_results()        # 保存结果
    
    # 辅助方法
    - _extract_bill_info()  # 提取账单信息
    - _find_bill_list()     # 查找账单列表（括号匹配）
    - _fallback_parse()     # 备用解析方法
```

## 四、核心功能设计

### 1. 日志解析策略（双重保障）

#### 策略一：标准JSON解析（优先）
```python
# 步骤：
1. 从日志行中提取JSON部分（查找 " - " 后的内容）
2. 使用括号匹配算法找到完整的JSON对象
3. 使用json.loads()解析
4. 直接提取字段：query、bill_info、reply
```

**优点：**
- 速度快、准确性高
- 能处理嵌套的JSON结构

**缺点：**
- 对JSON格式要求严格
- 遇到特殊字符（如中文引号）可能失败

#### 策略二：正则表达式备用方案（容错）
```python
# 当JSON解析失败时：
1. 使用正则表达式提取关键字段
2. 手动处理特殊字符（中文引号、转义字符）
3. 返回提取到的字段（可能不完整）
```

**优点：**
- 容错性强，能处理格式不规范的日志
- 即使部分字段缺失也能提取

**缺点：**
- 速度较慢
- 正则表达式较复杂

### 2. 账单信息提取设计

账单信息提取是项目的核心难点，因为：
- 账单信息嵌套在JSON字符串中（双重JSON）
- 可能出现在两个位置：`analysisResult.message_interpretation` 或 `promptParam.reference`
- 需要提取"账单:[...]"格式的列表
- 可能包含多个账单，需要提取最后一个完整的

**解决方案：**

```python
def _extract_bill_info():
    # 1. 优先从analysisResult提取
    # 2. 如果未找到，从promptParam提取
    # 3. 如果找到多个，返回最后一个（最完整的）
    
def _find_bill_list():
    # 使用括号匹配算法：
    # - 找到"账单:"关键字
    # - 定位到下一个'['开始位置
    # - 使用栈匹配括号，找到完整的列表
    # - 返回列表字符串
```

**设计亮点：**
- 使用括号匹配算法确保提取完整的列表结构
- 支持嵌套的字典和列表
- 从后往前查找，确保提取最后一个完整的账单

### 3. 字段提取设计

```python
result = {
    'query': None,           # 用户输入（必需字段）
    'bill_info': None,       # 账单信息（必需字段）
    'reply': None,           # 大模型回复（必需字段）
    'user_id': None,         # 扩展字段
    'session_id': None,      # 扩展字段
    # ... 其他字段
}
```

**设计原则：**
- **三个核心字段始终存在**：即使为None也要包含在结果中
- **扩展字段可选**：其他字段根据日志内容提取
- **缺失字段统一处理**：缺失字段设为None，输出时转换为null（JSON）或空字符串（CSV）

### 4. 输出格式设计

支持三种输出格式，满足不同使用场景：

#### JSON格式（默认）
- **用途**：程序处理、数据交换
- **特点**：保持数据类型，null表示缺失
- **适用场景**：后续程序处理、API调用

#### CSV格式
- **用途**：Excel分析、飞书表格导入
- **特点**：人类可读，缺失字段为空字符串
- **适用场景**：数据分析、报表制作

#### TXT格式
- **用途**：快速查看、日志归档
- **特点**：人类可读，格式友好
- **适用场景**：快速预览、文档记录

## 五、关键算法设计

### 1. JSON提取算法（括号匹配）

```python
# 从日志行中提取完整的JSON对象
1. 找到最后一个 " - " 的位置（日志格式标识）
2. 提取 " - " 后的内容作为JSON字符串
3. 使用括号匹配算法找到完整的JSON：
   - 遍历字符，计数 '{' 和 '}'
   - 当计数归零时，找到完整的JSON对象
4. 截取完整的JSON字符串
```

### 2. 账单列表提取算法（括号匹配）

```python
# 从文本中提取"账单:[...]"
1. 找到所有"账单:"关键字的位置
2. 从后往前查找（获取最后一个）
3. 定位到下一个'['位置
4. 使用栈匹配方括号：
   - 遇到'['计数+1
   - 遇到']'计数-1
   - 计数归零时找到完整列表
5. 返回列表字符串
```

### 3. Reply字段提取算法（特殊字符处理）

```python
# 处理reply字段中的中文引号
1. 找到"reply":"的位置
2. 定位到值开始的引号
3. 逐字符匹配，识别转义字符：
   - 遇到'\'标记转义状态
   - 遇到ASCII双引号且未转义时：
     - 检查后续字符是否为','或'}'
     - 如果是，说明是字段结束
     - 如果是中文引号或其他，继续
4. 提取完整的reply值
```

## 六、错误处理设计

### 1. 分级错误处理

```python
try:
    # 标准JSON解析
    log_data = json.loads(json_str)
except json.JSONDecodeError:
    # 降级到备用方案
    return self._fallback_parse(log_line)
except Exception:
    # 最后保障：返回空结果结构
    return {'query': None, 'bill_info': None, 'reply': None}
```

### 2. 缺失字段处理

```python
# 设计原则：即使字段缺失，也返回记录
# 三个核心字段始终存在（可能为None）
if 'query' not in result:
    result['query'] = None
if 'bill_info' not in result:
    result['bill_info'] = None
if 'reply' not in result:
    result['reply'] = None
```

## 七、扩展性设计

### 1. 字段扩展

```python
# 在parse_log_line()中添加新字段：
result['new_field'] = log_data.get('newField', None)

# 在_fallback_parse()中添加正则提取：
new_field_match = re.search(r'"newField"\s*:\s*"([^"]*)"', log_line)
if new_field_match:
    result['new_field'] = new_field_match.group(1)
```

### 2. 输出格式扩展

```python
# 在save_results()中添加新格式：
elif format == 'xml':
    # XML格式输出逻辑
elif format == 'excel':
    # Excel格式输出逻辑
```

### 3. 解析策略扩展

```python
# 可以添加更多解析策略：
def _parse_with_json5(self):
    # 使用json5库解析（更宽松）
    
def _parse_with_regex_advanced(self):
    # 使用更高级的正则表达式
```

## 八、性能考虑

### 1. 文件读取
- 逐行读取，避免一次性加载大文件到内存
- 使用生成器模式（enumerate）处理大文件

### 2. 解析优化
- 优先使用标准JSON解析（C实现，速度快）
- 只在必要时使用正则表达式（Python实现，较慢）

### 3. 内存管理
- 结果列表在内存中累积，适合中等规模文件
- 大文件可考虑流式处理（逐条写入）

## 九、测试设计

### 1. 单元测试
- `test_parser.py`：测试单行解析、文件解析
- 使用示例日志文件验证功能

### 2. 测试用例
- 完整字段的日志
- 缺失部分字段的日志
- 格式异常的日志
- 包含特殊字符的日志

## 十、设计模式应用

### 1. 策略模式（Strategy Pattern）
- JSON解析策略 vs 正则表达式策略
- 不同的输出格式策略（JSON/CSV/TXT）

### 2. 模板方法模式（Template Method）
- `parse_log_line()`定义了解析流程模板
- 具体提取逻辑在子方法中实现

### 3. 单一职责原则（SRP）
- `LogParser`类只负责解析
- `main.py`只负责命令行接口
- 每个方法职责明确

## 十一、设计亮点总结

1. **双重保障机制**：标准解析 + 备用方案，确保高成功率
2. **智能括号匹配**：准确提取嵌套的JSON和列表结构
3. **缺失字段容错**：即使字段缺失也输出记录，便于后续分析
4. **多格式输出**：满足不同使用场景的需求
5. **易于扩展**：代码结构清晰，便于添加新功能
6. **用户友好**：自动命名、结果预览、错误提示

## 十二、未来改进方向

1. **性能优化**：支持大文件流式处理
2. **功能扩展**：支持更多输出格式、更多字段提取
3. **配置化**：通过配置文件定义提取规则
4. **批量处理**：支持批量处理多个日志文件
5. **数据验证**：添加数据验证和清洗功能
6. **API接口**：提供REST API接口

