# 批量处理功能说明

## 功能概述

程序现在支持批量处理模式，可以一次性处理 `logs/` 文件夹下的所有日志文件，无需手动指定每个文件。

## 使用方法

### 基本用法

```bash
# 批量处理logs文件夹下的所有日志文件
python src/main.py
```

程序会自动：
1. 扫描 `logs/` 文件夹
2. 查找所有 `.log`, `.txt`, `.json` 文件
3. 逐个处理每个文件
4. 在 `output/` 目录下生成对应的结果文件

### 常用选项

```bash
# 批量处理并指定输出格式
python src/main.py -f csv        # CSV格式
python src/main.py -f txt        # TXT格式

# 批量处理并显示预览
python src/main.py --show

# 批量处理大文件（使用流式处理）
python src/main.py --stream

# 指定日志目录和输出目录
python src/main.py --logs-dir my_logs --output-dir my_output
```

### 输出文件命名

批量处理时，输出文件命名规则：
- 原始文件：`logs/modelAnalysis.2025-12-16.log`
- 输出文件：`output/modelAnalysis.2025-12-16_result.json`

如果指定了格式：
- `-f csv` → `output/modelAnalysis.2025-12-16_result.csv`
- `-f txt` → `output/modelAnalysis.2025-12-16_result.txt`

## 处理流程

### 批量处理流程

1. **扫描日志目录**
   - 查找 `logs/` 目录（可通过 `--logs-dir` 指定）
   - 查找所有支持的日志文件（`.log`, `.txt`, `.json`）

2. **逐个处理文件**
   - 显示处理进度：`[1/5] filename.log`
   - 解析日志文件
   - 生成结果文件

3. **显示统计信息**
   - 总文件数
   - 成功/失败数量
   - 总记录数
   - 输出目录路径

### 示例输出

```
============================================================
批量处理模式 - 找到 3 个日志文件
============================================================

[1/3] app.log
  成功解析 150 条记录
  结果已保存到: output/app_result.json (150 条记录)

[2/3] error.log
  警告: 没有解析到任何数据

[3/3] system.log
  ✓ 成功解析 250 条记录
  结果已保存到: output/system_result.json (250 条记录)

============================================================
批量处理完成
============================================================
总文件数: 3
成功: 2
失败: 1
总记录数: 400
输出目录: D:\GETLOG\output
```

## 单文件模式 vs 批量模式

### 单文件模式

适用场景：
- 只处理一个特定文件
- 需要自定义输出路径
- 临时测试或调试

```bash
python src/main.py logs/specific_file.log -o custom_output.json
```

### 批量模式

适用场景：
- 处理多个日志文件
- 定期批量处理日志
- 自动化处理流程

```bash
python src/main.py  # 自动处理logs目录下的所有文件
```

## 性能建议

### 小文件批量处理
- 使用默认模式（内存模式）
- 处理速度快，内存占用小

### 大文件批量处理
- 使用 `--stream` 选项
- 内存占用恒定，适合大文件

```bash
# 处理大量大文件
python src/main.py --stream
```

## 错误处理

批量处理时，如果某个文件处理失败：
- 不会中断整个处理流程
- 会在控制台显示错误信息
- 继续处理下一个文件
- 最终统计中会显示失败数量

## 文件查找规则

程序会查找以下格式的文件：
- `*.log` - 标准日志文件
- `*.txt` - 文本日志文件
- `*.json` - JSON格式日志文件

**注意**：程序只查找文件，不会递归查找子目录。

如果需要处理子目录中的文件，可以：
1. 使用脚本将文件复制到 `logs/` 目录
2. 分别指定各个子目录处理

## 自定义目录

```bash
# 从不同目录读取日志
python src/main.py --logs-dir /path/to/logs

# 输出到不同目录
python src/main.py --output-dir /path/to/output

# 同时指定两个目录
python src/main.py --logs-dir /path/to/logs --output-dir /path/to/output
```

## 常见问题

### Q: 如何处理子目录中的日志文件？
A: 当前版本不支持递归查找。可以将文件复制到logs目录，或分别处理各个目录。

### Q: 批量处理时如何跳过某些文件？
A: 可以将不需要处理的文件移出 `logs/` 目录，或重命名为不支持的扩展名。

### Q: 批量处理失败的文件会怎样？
A: 失败的文件会被记录在统计信息中，但不会影响其他文件的处理。

### Q: 如何查看批量处理的详细日志？
A: 使用 `--show` 选项可以查看每个文件的解析结果预览。

